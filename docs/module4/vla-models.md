---
sidebar_position: 1
title: VLA Models
---

# Vision-Language-Action (VLA)

## Convergence of AI and Robotics
[cite_start]This module explores the convergence of **Large Language Models (LLMs)** and **Robotics**[cite: 68, 69]. 

[Image of Vision-Language-Action model architecture]


## Cognitive Planning
[cite_start]We utilize **Cognitive Planning** where LLMs translate natural language commands (e.g., "Clean the room") into a sequence of executable **ROS 2 actions**[cite: 71].

## Capstone Project: The Autonomous Humanoid
The final project involves a simulated robot that:
1.  Receives a voice command.
2.  Plans a path.
3.  Navigates obstacles.
4.  Identifies an object using computer vision.
5.  [cite_start]Manipulates the object[cite: 72].